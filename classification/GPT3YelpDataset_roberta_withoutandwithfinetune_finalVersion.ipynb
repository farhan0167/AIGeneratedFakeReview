{"cells":[{"cell_type":"markdown","metadata":{"id":"M8dHKVe-5ZUu"},"source":["*This is fakeRoBERTa*"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7CnEB-G_5dz_","executionInfo":{"status":"ok","timestamp":1671299301546,"user_tz":300,"elapsed":17979,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"b036cd0d-5648-4f9a-d720-febf4d0561d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 28.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 75.4 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 57.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"kfOvRZvk5ZUx","executionInfo":{"status":"ok","timestamp":1671299316268,"user_tz":300,"elapsed":11240,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import RobertaForSequenceClassification, RobertaTokenizer\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"6TZbkUfc5ZUz","executionInfo":{"status":"ok","timestamp":1671299317070,"user_tz":300,"elapsed":806,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"QOjMM66H5ZUz","executionInfo":{"status":"ok","timestamp":1671299317070,"user_tz":300,"elapsed":5,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["encoded_label_dict = {\"CG\" : 0, \"OR\" : 1}\n","def encode_label(x):\n","    return encoded_label_dict.get(x,-1)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0XryO1sYp73R","executionInfo":{"status":"ok","timestamp":1671299341662,"user_tz":300,"elapsed":24596,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"7b8938d4-1192-4719-8142-2212313ec3c9"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!ls /content/drive/MyDrive/YelpDataset/generatedData/GPT3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nIfAyjpK9BFV","executionInfo":{"status":"ok","timestamp":1671299344770,"user_tz":300,"elapsed":3111,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"a8007227-8386-4b3c-82a9-b383f5a671e2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated_Sentences_RestaurantGPT3.csv\n","Generated_Sentences_RestaurantGPT3UnProcessed.csv\n"]}]},{"cell_type":"code","source":["%cp /content/drive/MyDrive/YelpDataset/generatedData/GPT3/Generated_Sentences_RestaurantGPT3.csv /content/"],"metadata":{"id":"G-qT2rAfp70b","executionInfo":{"status":"ok","timestamp":1671299348094,"user_tz":300,"elapsed":1344,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"AomgyN9b5ZUz","executionInfo":{"status":"ok","timestamp":1671299350810,"user_tz":300,"elapsed":307,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["df = pd.read_csv(\"Generated_Sentences_RestaurantGPT3.csv\", encoding='latin-1')"]},{"cell_type":"code","source":["df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"oRv7zieLqxJh","executionInfo":{"status":"ok","timestamp":1671299352847,"user_tz":300,"elapsed":330,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"dd02c607-a834-4558-ecfd-c3672844aeb2"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      category  rating label  \\\n","0  Restaurants     4.0    CG   \n","1  Restaurants     4.0    OR   \n","2  Restaurants     4.0    CG   \n","3  Restaurants     4.5    OR   \n","4  Restaurants     3.5    CG   \n","\n","                                               text_  \n","0  Excellent food.  Large servings.  Great burger...  \n","1  best chicken with green and yellow sauce cilan...  \n","2  Hit the spot. Great food, friendly servers. Pr...  \n","3  Consider yourself lucky if you can get one, bo...  \n","4  Well, I thought it was awesome. The restaurant...  "],"text/html":["\n","  <div id=\"df-ca17d531-1192-4627-a11d-59fdcf5845d5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>category</th>\n","      <th>rating</th>\n","      <th>label</th>\n","      <th>text_</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Restaurants</td>\n","      <td>4.0</td>\n","      <td>CG</td>\n","      <td>Excellent food.  Large servings.  Great burger...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Restaurants</td>\n","      <td>4.0</td>\n","      <td>OR</td>\n","      <td>best chicken with green and yellow sauce cilan...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Restaurants</td>\n","      <td>4.0</td>\n","      <td>CG</td>\n","      <td>Hit the spot. Great food, friendly servers. Pr...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Restaurants</td>\n","      <td>4.5</td>\n","      <td>OR</td>\n","      <td>Consider yourself lucky if you can get one, bo...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Restaurants</td>\n","      <td>3.5</td>\n","      <td>CG</td>\n","      <td>Well, I thought it was awesome. The restaurant...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca17d531-1192-4627-a11d-59fdcf5845d5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ca17d531-1192-4627-a11d-59fdcf5845d5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ca17d531-1192-4627-a11d-59fdcf5845d5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pxk9psqWq0mF","executionInfo":{"status":"ok","timestamp":1671299356787,"user_tz":300,"elapsed":1104,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"0480969e-a7b5-47ef-f1b6-8c1e82aa3fb4"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1042, 4)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["df.dropna(inplace=True)"],"metadata":{"id":"JUl9vgburQXM","executionInfo":{"status":"ok","timestamp":1671299357583,"user_tz":300,"elapsed":2,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bmnvho6tq6RK","executionInfo":{"status":"ok","timestamp":1671299359330,"user_tz":300,"elapsed":1,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"24e4552e-429e-455a-c07d-91e9a169f563"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1042, 4)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","execution_count":13,"metadata":{"id":"w-pNJhvu5ZU0","executionInfo":{"status":"ok","timestamp":1671299360708,"user_tz":300,"elapsed":2,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["df[\"target\"] = df[\"label\"].apply(lambda x: encode_label(x))"]},{"cell_type":"code","source":["df[\"category\"].unique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZYWo-BZ2tTLq","executionInfo":{"status":"ok","timestamp":1671299361968,"user_tz":300,"elapsed":2,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"60f061f7-8834-4a5b-aeb4-f09bd82afc11"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['Restaurants'], dtype=object)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["df.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"jdzQjCVv-1dV","executionInfo":{"status":"ok","timestamp":1671299366750,"user_tz":300,"elapsed":321,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"4fba20dd-ae20-4f4d-ee72-d3a9b492459b"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["            rating      target\n","count  1042.000000  1042.00000\n","mean      3.847889     0.50000\n","std       0.618045     0.50024\n","min       1.500000     0.00000\n","25%       3.500000     0.00000\n","50%       4.000000     0.50000\n","75%       4.500000     1.00000\n","max       5.000000     1.00000"],"text/html":["\n","  <div id=\"df-915aac77-4d6a-4c93-ba00-3d3b35381e9d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>rating</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1042.000000</td>\n","      <td>1042.00000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>3.847889</td>\n","      <td>0.50000</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.618045</td>\n","      <td>0.50024</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.500000</td>\n","      <td>0.00000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>3.500000</td>\n","      <td>0.00000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>4.000000</td>\n","      <td>0.50000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>4.500000</td>\n","      <td>1.00000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>5.000000</td>\n","      <td>1.00000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-915aac77-4d6a-4c93-ba00-3d3b35381e9d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-915aac77-4d6a-4c93-ba00-3d3b35381e9d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-915aac77-4d6a-4c93-ba00-3d3b35381e9d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}]},{"cell_type":"code","execution_count":16,"metadata":{"id":"heKW5CTP5ZU0","executionInfo":{"status":"ok","timestamp":1671299370012,"user_tz":300,"elapsed":317,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["\n","MAX_LEN = 256\n","TRAIN_BATCH_SIZE = 8\n","VALID_BATCH_SIZE = 8\n","EPOCHS = 1\n","LEARNING_RATE = 1e-05"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"qFoMZ9uY5ZU1","executionInfo":{"status":"ok","timestamp":1671299373117,"user_tz":300,"elapsed":328,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["class Triage(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        \n","    def __getitem__(self, index):\n","        title = str(self.data.text_[index])\n","        title = \" \".join(title.split())\n","        inputs = self.tokenizer.encode_plus(\n","            title,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True,\n","            truncation=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'targets': torch.tensor(self.data.target[index], dtype=torch.long)\n","        } \n","    \n","    def __len__(self):\n","        return self.len"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"KyKAYaB5NN5l","executionInfo":{"status":"ok","timestamp":1671299395911,"user_tz":300,"elapsed":313,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["from transformers import RobertaForSequenceClassification, RobertaTokenizer\n","import torch"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["bc71df8cfb87440c92129db5b22f910d","30f45a597635486cbfaa6d585c40e758","993aa808bc2f4dd08d65df45693838e6","6747ad0f8359439cb0b4331a1156b3df","a0f0597dd3514c3d87af73707a1762a6","f8e976ed82504353a909161e2587329f","cbbeb7a94fdf4a01a6d4aaa2c9b6e2ed","46984893dcbf40cabcba3bdf5084e734","ea4a8f6de8004342ab2a81d5e6e6347e","3f73af6f92a1467a824b0d1335d0833a","5cc2200fe6da402fbb37627d5232ad4d","bb0f96e3bd80463e9388281c4d5fb9d2","39b2ff06312e4a4cbd81009e999fc274","28850980c79e4485b8fb6794b8380658","422a259495eb4384939119bab6bac7af","5ac7148e84c74512a730f4b96c328807","122e22163da24ecbabe9893643a0d647","820489357dd94b5bb503007086c1c16f","275848407b5e44969bb909acd4671d80","bf5a9cbd92ef405188cedf7d98fdd37c","0e6b796efef94c8ca594f8dcf2bd4ffe","a03201986de5467db25728c363972482","72c672cfe00143529fc6511a58a2533b","674526a8676a4fa8b772c84cffb067af","24dc5e4511054a8595de957d995a1b7e","652a7e3ce8ba4161ae41d1f3b663a734","86c0104f571949f0b448818af9d6b61f","11150fe4d84340668d341f3365c2b867","6670dfadbb734cecb2bdf61a6a723754","f9e244d317694dc3886c81e89cdd72f0","d1609fc5354f47c59af870f3eb3b259a","889e2e58d7b54feeb5f9bb4635150311","8b6654632d0c47e6923628a2f4b5bed9"]},"id":"Dr29hGUFNN5l","executionInfo":{"status":"ok","timestamp":1671299408493,"user_tz":300,"elapsed":11017,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"f2e67260-5294-4a8e-f197-4ce9c7665a62"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc71df8cfb87440c92129db5b22f910d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb0f96e3bd80463e9388281c4d5fb9d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72c672cfe00143529fc6511a58a2533b"}},"metadata":{}}],"source":["model_name = \"roberta-base\"\n","tokenizer = RobertaTokenizer.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"-XtXDnRi5ZU2","outputId":"c0385282-c0d7-4101-8169-32df03c27904","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671299410902,"user_tz":300,"elapsed":357,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["FULL Dataset: (1042, 5)\n","TRAIN Dataset: (833, 5)\n","VALID Dataset: (209, 5)\n"]}],"source":["# Creating the dataset and dataloader\n","train_dataset, valid_dataset = train_test_split(df, test_size=0.2, shuffle=True, stratify=None, random_state=2021)\n","train_dataset = train_dataset.reset_index(drop=True)\n","valid_dataset = valid_dataset.reset_index(drop=True)\n","\n","print(\"FULL Dataset: {}\".format(df.shape))\n","print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n","print(\"VALID Dataset: {}\".format(valid_dataset.shape))\n","\n","training_set = Triage(train_dataset, tokenizer, MAX_LEN)\n","testing_set = Triage(valid_dataset, tokenizer, MAX_LEN)"]},{"cell_type":"code","source":[],"metadata":{"id":"S3I816R3MVOx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Without Finetune on the New Data"],"metadata":{"id":"hEb53MIeMoOR"}},{"cell_type":"code","source":["#/content/drive/MyDrive/YelpDataset/Roberta replace it with whereever you have the finetuned model saved in your drive\n","%cp -r /content/drive/MyDrive/YelpDataset/Roberta /content/"],"metadata":{"id":"90aQNES1Mk0r","executionInfo":{"status":"ok","timestamp":1671299436163,"user_tz":300,"elapsed":13288,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["output_model_file = '/content/Roberta/ft-roberta-yelpreviews_kitchen.pt'"],"metadata":{"id":"fn5S7YN_Mk0s","executionInfo":{"status":"ok","timestamp":1671299446296,"user_tz":300,"elapsed":338,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","execution_count":24,"metadata":{"id":"jPwE7eBSMk0s","executionInfo":{"status":"ok","timestamp":1671299455320,"user_tz":300,"elapsed":6669,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["# model = torch.load('../../data/classification/models/ft-roberta-amazonreviews.pt')\n","model = torch.load(output_model_file)"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"UnMBMw3LMk0s","executionInfo":{"status":"ok","timestamp":1671299458450,"user_tz":300,"elapsed":309,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["def predict(query, model, tokenizer, device=\"cuda\"):\n","    tokens = tokenizer.encode(query)\n","    all_tokens = len(tokens)\n","    tokens = tokens[:tokenizer.model_max_length - 2]\n","    used_tokens = len(tokens)\n","    tokens = torch.tensor([tokenizer.bos_token_id] + tokens + [tokenizer.eos_token_id]).unsqueeze(0)\n","    mask = torch.ones_like(tokens)\n","\n","    with torch.no_grad():\n","        logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n","        probs = logits.softmax(dim=-1)\n","\n","    fake, real = probs.detach().cpu().flatten().numpy().tolist()\n","    return real"]},{"cell_type":"code","execution_count":26,"metadata":{"outputId":"37c55bcd-79bf-4a39-bece-530114e1b623","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671299463707,"user_tz":300,"elapsed":3232,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"x1rMa8k9Mk0s"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.999467670917511"]},"metadata":{},"execution_count":26}],"source":["query = \"\"\"I work in the wedding industry and have to work long days, on my feet, outside in the heat, and have to look professional. I've spent a ridiculous amount of money on high end dress shoes like Merrels and just have not been able to find a pair that are comfortable to wear all day. Both for my feet and my back. Enter the Sanuk yoga sling!!! These shoes are amazingly comfortable. Though, I will admit it took a few wears to get used to the feel of the yoga matte bottom. At first, it felt a little \"sticky\" to me, and the fabric part that goes through the toe area was a little thick and took some getting used to. I wore them for a few days before taking them out on a job and I can't get over how comfortable they are. Ii have been wearing these shoes now for 3 months, every work day and I am THRILLED. No more back pain, no more sore feet. I also wear these sometimes during my off time,mans every time I wear them, I get compliments on how cute and comfortable they look. The great thing about these shoes is the yoga matte bottom. It helps your feet grip to the shoe a bit, so your foot can just walk normally, without having to grip the shoe. You may not realize it, but with a lot of Sandals, your foot is having to work to keep the shoe on, changing the way you walk and stand and ultimately causing foot and back pain. Not with these! Also, the soft linen sits comfortably on your skin and breathes nicely in the heat. The only downside is the funky tan lines, which is why I am sure to alternate shoes on my days off, especially if I plan to be outside for most of the day. If it were not for that, I think these might be the only shoes I'd wear all summer. If you are looking for a reasonable priced, comfortable shoe that you can wear and walk in all day.\"\"\"\n","predict(query,model,tokenizer)"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"nYrkn53DMk0s","executionInfo":{"status":"ok","timestamp":1671299467945,"user_tz":300,"elapsed":2917,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["preds, preds_probas = [],[]\n","for i, row in valid_dataset.iterrows():\n","    query = row[\"text_\"]\n","    pred = predict(query,model,tokenizer)\n","    preds_probas.append(pred)\n","    if pred >= 0.5:\n","        preds.append(1)\n","    else:\n","        preds.append(0)"]},{"cell_type":"code","execution_count":28,"metadata":{"outputId":"84a27dce-37df-4566-f8ac-1f46f064e668","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671299474094,"user_tz":300,"elapsed":304,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"T4_c9YPEMk0s"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[96, 10],\n","       [ 5, 98]])"]},"metadata":{},"execution_count":28}],"source":["from sklearn.metrics import confusion_matrix\n","y_true = valid_dataset.target.values\n","y_pred = preds\n","confusion_matrix(y_true,y_pred)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"XQBTPadFMk0s","executionInfo":{"status":"ok","timestamp":1671299478025,"user_tz":300,"elapsed":330,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n","acc = accuracy_score(y_true,y_pred)\n","precision = precision_score(y_true,y_pred)\n","recall = recall_score(y_true,y_pred)"]},{"cell_type":"code","execution_count":30,"metadata":{"outputId":"686a195e-39e7-4d37-ba70-8ec51244c191","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671299479932,"user_tz":300,"elapsed":338,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"9S0gA3XYMk0t"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 92.82296650717703; Precision:90.74074074074075; Recall:95.14563106796116\n"]}],"source":["print(f\"Accuracy: {acc*100}; Precision:{precision*100}; Recall:{recall*100}\")"]},{"cell_type":"code","execution_count":31,"metadata":{"outputId":"4de9007e-a091-4f3e-a24f-eced5bbf5a88","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671299482789,"user_tz":300,"elapsed":304,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"Iw1oiQqUMk0t"},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","          CG       0.95      0.91      0.93       106\n","          OR       0.91      0.95      0.93       103\n","\n","    accuracy                           0.93       209\n","   macro avg       0.93      0.93      0.93       209\n","weighted avg       0.93      0.93      0.93       209\n","\n"]}],"source":["print(classification_report(y_true, y_pred, target_names=[\"CG\",\"OR\"]))"]},{"cell_type":"markdown","metadata":{"id":"gz-OJJXDMk0t"},"source":["#### Writing predictions to disc"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"ZI5uJWXsMk0t","executionInfo":{"status":"ok","timestamp":1671299492257,"user_tz":300,"elapsed":309,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["preds_df_rows = []\n","for i, row in valid_dataset.iterrows():\n","    query = row[\"text_\"]\n","    pred_prob = preds_probas[i]\n","    pred_label = preds[i]\n","    preds_df_rows.append([pred_prob,pred_label])\n","preds_df = pd.DataFrame(preds_df_rows, columns=[\"Finetune_Roberta_Model_Probability\",\"Finetune_Roberta_Model_Prediction\"])"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"tCEgNcABMk0t","executionInfo":{"status":"ok","timestamp":1671299499976,"user_tz":300,"elapsed":308,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["preds_df.to_csv(\"roberta_predictionsGPT3WithoutFineTune2.csv\", index=None)"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"gqdTsAG8Mk0t","executionInfo":{"status":"ok","timestamp":1671299504074,"user_tz":300,"elapsed":2,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["%cp /content/roberta_predictionsGPT3WithoutFineTune2.csv /content/drive/MyDrive/YelpDataset/Roberta"]},{"cell_type":"markdown","source":["#Finetune on New Data"],"metadata":{"id":"9KtZ56mtMs-x"}},{"cell_type":"code","execution_count":35,"metadata":{"id":"gjyo5zz25ZU3","executionInfo":{"status":"ok","timestamp":1671299507747,"user_tz":300,"elapsed":2,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","valid_params = {'batch_size': VALID_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","training_loader = DataLoader(training_set, **train_params)\n","testing_loader = DataLoader(testing_set, **valid_params)"]},{"cell_type":"code","source":[],"metadata":{"id":"eqte9ahd_7AS"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"status":"ok","timestamp":1671299515388,"user_tz":300,"elapsed":305,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"EYpV-gtW_70F"},"outputs":[],"source":["from transformers import RobertaForSequenceClassification, RobertaTokenizer\n","import torch"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"status":"ok","timestamp":1671299517724,"user_tz":300,"elapsed":951,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"FrZw0I0w_70F"},"outputs":[],"source":["model_name = \"roberta-base\"\n","tokenizer = RobertaTokenizer.from_pretrained(model_name)"]},{"cell_type":"code","source":["output_model_file = '/content/Roberta/ft-roberta-yelpreviews_kitchen.pt'"],"metadata":{"executionInfo":{"status":"ok","timestamp":1671299519419,"user_tz":300,"elapsed":305,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"R7w9pR5F_70G"},"execution_count":38,"outputs":[]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"status":"ok","timestamp":1671299521750,"user_tz":300,"elapsed":663,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"jT61UU1v_70G"},"outputs":[],"source":["# model = torch.load('../../data/classification/models/ft-roberta-amazonreviews.pt')\n","model = torch.load(output_model_file)"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"Xa8x65Ra5ZU3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671299523294,"user_tz":300,"elapsed":482,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"76fed187-49a4-45b4-9d0a-d3abddbf6d22"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["RobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":40}],"source":["#model = RobertaForSequenceClassification.from_pretrained(model_name)\n","model.to(device)"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"GqtQtnea5ZU3","executionInfo":{"status":"ok","timestamp":1671299527340,"user_tz":300,"elapsed":319,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["# Creating the optimizer\n","optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"Yun4Z3mU5ZU4","executionInfo":{"status":"ok","timestamp":1671299529580,"user_tz":300,"elapsed":309,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["# Function to calcuate the accuracy of the model\n","def calcuate_accu(big_idx, targets):\n","    n_correct = (big_idx==targets).sum().item()\n","    return n_correct"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"vgqXCUj65ZU4","executionInfo":{"status":"ok","timestamp":1671299532072,"user_tz":300,"elapsed":303,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["# Defining the training function on the 80% of the dataset for tuning the roberta model\n","def train(epoch):\n","    tr_loss = 0\n","    n_correct = 0\n","    nb_tr_steps = 0\n","    nb_tr_examples = 0\n","    model.train()\n","    for _,data in enumerate(training_loader, 0):\n","        ids = data['ids'].to(device, dtype = torch.long)\n","        mask = data['mask'].to(device, dtype = torch.long)\n","        targets = data['targets'].to(device, dtype = torch.long)\n","        \n","        optimizer.zero_grad()\n","        outputs = model(ids, attention_mask=mask, labels=targets)\n","        loss = outputs.loss\n","        logits = outputs.logits\n","        tr_loss += loss\n","        big_val, big_idx = torch.max(logits, dim=1)\n","        n_correct += calcuate_accu(big_idx, targets)\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples+=targets.size(0)\n","        \n","        if _!=0 and _%100==0:\n","            loss_step = tr_loss/nb_tr_steps\n","            accu_step = (n_correct*100)/nb_tr_examples \n","            print(f\"Training Loss per 100 steps: {loss_step}\")\n","            print(f\"Training Accuracy per 100 steps: {accu_step}\")\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n","    epoch_loss = tr_loss/nb_tr_steps\n","    epoch_accu = (n_correct*100)/nb_tr_examples\n","    print(f\"Training Loss Epoch: {epoch_loss}\")\n","    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n","\n","    return "]},{"cell_type":"code","execution_count":44,"metadata":{"id":"ODbhfn2m5ZU4","executionInfo":{"status":"ok","timestamp":1671299534241,"user_tz":300,"elapsed":1,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["def valid(model, testing_loader):\n","    model.eval()\n","    n_correct = 0\n","    n_wrong = 0\n","    total = 0\n","    tr_loss = 0\n","    nb_tr_steps = 0\n","    nb_tr_examples = 0\n","    with torch.no_grad():\n","        for _, data in enumerate(testing_loader, 0):\n","            ids = data['ids'].to(device, dtype = torch.long)\n","            mask = data['mask'].to(device, dtype = torch.long)\n","            targets = data['targets'].to(device, dtype = torch.long)\n","            outputs = model(ids, attention_mask=mask, labels=targets)\n","            loss = outputs.loss\n","            logits = outputs.logits\n","            tr_loss += loss\n","            big_val, big_idx = torch.max(logits, dim=1)\n","            n_correct += calcuate_accu(big_idx, targets)\n","\n","            nb_tr_steps += 1\n","            nb_tr_examples+=targets.size(0)\n","            \n","            if _!=0 and _%100==0:\n","                loss_step = tr_loss/nb_tr_steps\n","                accu_step = (n_correct*100)/nb_tr_examples\n","                print(f\"Validation Loss per 100 steps: {loss_step}\")\n","                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n","    epoch_loss = tr_loss/nb_tr_steps\n","    epoch_accu = (n_correct*100)/nb_tr_examples\n","    print(f\"Validation Loss Epoch: {epoch_loss}\")\n","    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n","    \n","    return epoch_accu\n"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"a5oQke255ZU5","outputId":"453c3b67-2714-453d-81e4-492558dfff4d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671299536856,"user_tz":300,"elapsed":312,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":45}],"source":["tokenizer.pad_token_id"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"3LZyW9EG5ZU5","outputId":"bfa7c1b2-3e98-41e5-b898-f9f5a8d9974b","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671299573689,"user_tz":300,"elapsed":35549,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Training Loss per 100 steps: 0.19425369799137115\n","Training Accuracy per 100 steps: 93.31683168316832\n","The Total Accuracy for Epoch 0: 93.51740696278512\n","Training Loss Epoch: 0.1890932023525238\n","Training Accuracy Epoch: 93.51740696278512\n"]}],"source":["for epoch in range(EPOCHS):\n","    train(epoch)\n","# 4000 -> 10min\n","# 40,000 -> 100min \n","# start from 17:54 -> 18:10"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"QujCBAmE5ZU5","outputId":"9c8fe2c6-1835-46cf-f02b-dc8095a89c08","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671299590300,"user_tz":300,"elapsed":3478,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Validation Loss Epoch: 0.12739889323711395\n","Validation Accuracy Epoch: 95.69377990430623\n","Accuracy on validation data = 95.69%\n"]}],"source":["acc = valid(model, testing_loader)\n","print(\"Accuracy on validation data = %0.2f%%\" % acc)"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"_L11XpEa5ZU6","outputId":"77ed06ef-2a46-4659-e00d-2c1e85fed8ba","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671299607744,"user_tz":300,"elapsed":1823,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["All files saved\n"]}],"source":["# Save the model\n","# output_model_file = '../../data/classification/models/ft-roberta-amazonreviews.pt'\n","output_model_file = 'ft-roberta-yelpreviews_kitchenGPT3Finetuned2.pt'\n","\n","model_to_save = model\n","torch.save(model_to_save, output_model_file)\n","\n","print('All files saved')"]},{"cell_type":"code","source":["%cp /content/ft-roberta-yelpreviews_kitchenGPT3Finetuned2.pt /content/drive/MyDrive/YelpDataset/Roberta"],"metadata":{"id":"OAo1xt7Ww4QP","executionInfo":{"status":"ok","timestamp":1671299614857,"user_tz":300,"elapsed":2046,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"execution_count":49,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h3KqRz1x5ZU6"},"source":["#### Inference"]},{"cell_type":"code","source":["\"\"\"\n","#use this if you need to mount your drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\"\"\""],"metadata":{"id":"gF4BOhu3W1eJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#/content/drive/MyDrive/YelpDataset/Roberta replace it with whereever you have the finetuned model saved in your drive\n","!ls /content/drive/MyDrive/YelpDataset/Roberta"],"metadata":{"id":"V8ciFN0jWn0T","executionInfo":{"status":"ok","timestamp":1671299638093,"user_tz":300,"elapsed":315,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e4595298-0388-427a-c957-d8e2c294a348"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["ft-roberta-yelpreviews_kitchenGPT3Finetuned2.pt\n","ft-roberta-yelpreviews_kitchenGPT3Finetuned.pt\n","ft-roberta-yelpreviews_kitchen.pt\n","roberta_predictions.csv\n","roberta_predictionsGPT3FineTune.csv\n","roberta_predictionsGPT3WithoutFineTune2.csv\n","roberta_predictionsGPT3WithoutFineTune.csv\n"]}]},{"cell_type":"code","execution_count":51,"metadata":{"id":"zWsxRtsP5ZU6","executionInfo":{"status":"ok","timestamp":1671299652242,"user_tz":300,"elapsed":346,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["from transformers import RobertaForSequenceClassification, RobertaTokenizer\n","import torch"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"Nei7aOZa5ZU6","executionInfo":{"status":"ok","timestamp":1671299655623,"user_tz":300,"elapsed":1302,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["model_name = \"roberta-base\"\n","tokenizer = RobertaTokenizer.from_pretrained(model_name)"]},{"cell_type":"code","source":["output_model_file = 'ft-roberta-yelpreviews_kitchenGPT3Finetuned2.pt'"],"metadata":{"id":"5dvheISk-KX2","executionInfo":{"status":"ok","timestamp":1671299658105,"user_tz":300,"elapsed":1,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","execution_count":54,"metadata":{"id":"IO1MzkX85ZU7","executionInfo":{"status":"ok","timestamp":1671299661058,"user_tz":300,"elapsed":680,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["# model = torch.load('../../data/classification/models/ft-roberta-amazonreviews.pt')\n","model = torch.load(output_model_file)"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"ZmejYIH_5ZU7","outputId":"17e679d0-f258-4ab8-fd87-5a1a288d595f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671299663943,"user_tz":300,"elapsed":304,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Real Probability: 0.997197151184082\n","Fake Probability: 0.0028028751257807016\n"]}],"source":["device=\"cuda\"\n","query = \"\"\"I work in the wedding industry and have to work long days, on my feet, outside in the heat, and have to look professional. I've spent a ridiculous amount of money on high end dress shoes like Merrels and just have not been able to find a pair that are comfortable to wear all day. Both for my feet and my back. Enter the Sanuk yoga sling!!! These shoes are amazingly comfortable. Though, I will admit it took a few wears to get used to the feel of the yoga matte bottom. At first, it felt a little \"sticky\" to me, and the fabric part that goes through the toe area was a little thick and took some getting used to. I wore them for a few days before taking them out on a job and I can't get over how comfortable they are. Ii have been wearing these shoes now for 3 months, every work day and I am THRILLED. No more back pain, no more sore feet. I also wear these sometimes during my off time,mans every time I wear them, I get compliments on how cute and comfortable they look. The great thing about these shoes is the yoga matte bottom. It helps your feet grip to the shoe a bit, so your foot can just walk normally, without having to grip the shoe. You may not realize it, but with a lot of Sandals, your foot is having to work to keep the shoe on, changing the way you walk and stand and ultimately causing foot and back pain. Not with these! Also, the soft linen sits comfortably on your skin and breathes nicely in the heat. The only downside is the funky tan lines, which is why I am sure to alternate shoes on my days off, especially if I plan to be outside for most of the day. If it were not for that, I think these might be the only shoes I'd wear all summer. If you are looking for a reasonable priced, comfortable shoe that you can wear and walk in all day.\"\"\"\n","tokens = tokenizer.encode(query,return_tensors=\"pt\")\n","all_tokens = len(tokens)\n","mask = torch.ones_like(tokens)\n","\n","with torch.no_grad():\n","    logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n","    probs = logits.softmax(dim=-1)\n","\n","fake, real = probs.detach().cpu().flatten().numpy().tolist()\n","\n","print(f\"Real Probability: {real}\\nFake Probability: {fake}\")"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"iLO8kzht5ZU7","outputId":"a768beb9-034e-4ecf-9fc9-07f110820457","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671299666189,"user_tz":300,"elapsed":10,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Real Probability: 0.026194270700216293\n","Fake Probability: 0.9738057255744934\n"]}],"source":["#is fake\n","device=\"cuda\"\n","query = \"\"\"terrible servile. not worthy of a second visit.We decided to try this place for the\"\"\"\n","tokens = tokenizer.encode(query,return_tensors=\"pt\")\n","all_tokens = len(tokens[0])\n","mask = torch.ones_like(tokens)\n","\n","with torch.no_grad():\n","    logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n","    probs = logits.softmax(dim=-1)\n","\n","fake, real = probs.detach().cpu().flatten().numpy().tolist()\n","\n","print(f\"Real Probability: {real}\\nFake Probability: {fake}\")"]},{"cell_type":"code","source":["#is original from the dataset\n","device=\"cuda\"\n","query = \"\"\"Wonderfully prepared and beautifully presented food. Staff is very friendly. Bright and clean.\"\"\"\n","tokens = tokenizer.encode(query,return_tensors=\"pt\")\n","all_tokens = len(tokens[0])\n","mask = torch.ones_like(tokens)\n","\n","with torch.no_grad():\n","    logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n","    probs = logits.softmax(dim=-1)\n","\n","fake, real = probs.detach().cpu().flatten().numpy().tolist()\n","\n","print(f\"Real Probability: {real}\\nFake Probability: {fake}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k8XYcdpFyhdD","executionInfo":{"status":"ok","timestamp":1671299669548,"user_tz":300,"elapsed":308,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"480eab5a-6e19-48bd-ea7d-f177eb76048c"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["Real Probability: 0.29891064763069153\n","Fake Probability: 0.7010893225669861\n"]}]},{"cell_type":"code","source":["#is original from the dataset\n","device=\"cuda\"\n","query = \"\"\"Consistently good standard American and Mexican breakfast fare. The coffee not so impressive.\"\"\"\n","tokens = tokenizer.encode(query,return_tensors=\"pt\")\n","all_tokens = len(tokens[0])\n","mask = torch.ones_like(tokens)\n","\n","with torch.no_grad():\n","    logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n","    probs = logits.softmax(dim=-1)\n","\n","fake, real = probs.detach().cpu().flatten().numpy().tolist()\n","\n","print(f\"Real Probability: {real}\\nFake Probability: {fake}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zs71pw_oyYOz","executionInfo":{"status":"ok","timestamp":1671299676017,"user_tz":300,"elapsed":2,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"f9e7d99b-4f45-43bf-e332-543f0cfb2b24"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Real Probability: 0.6281370520591736\n","Fake Probability: 0.3718630075454712\n"]}]},{"cell_type":"code","source":["#I wrote it myself\n","device=\"cuda\"\n","query = \"\"\"I've been going here for a 2 years but in the last few months the quality of their food has become really bad. The portion size has reduced and their food doesn't taste as good as it used to.\"\"\"\n","tokens = tokenizer.encode(query,return_tensors=\"pt\")\n","all_tokens = len(tokens[0])\n","mask = torch.ones_like(tokens)\n","\n","with torch.no_grad():\n","    logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n","    probs = logits.softmax(dim=-1)\n","\n","fake, real = probs.detach().cpu().flatten().numpy().tolist()\n","\n","print(f\"Real Probability: {real}\\nFake Probability: {fake}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L3NLjN6uy07p","executionInfo":{"status":"ok","timestamp":1671299683475,"user_tz":300,"elapsed":486,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"3f0bb2e7-5607-4a27-8275-f22f75fb1a32"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Real Probability: 0.36147746443748474\n","Fake Probability: 0.6385225653648376\n"]}]},{"cell_type":"code","source":["#Is original\n","device=\"cuda\"\n","query = \"\"\"Good pizza, fair amount of toppings but they came kind of askew. The subs had a very generous amount of thinly sliced n breaded chicken on them. Decent flavor overall.\"\"\"\n","tokens = tokenizer.encode(query,return_tensors=\"pt\")\n","all_tokens = len(tokens[0])\n","mask = torch.ones_like(tokens)\n","\n","with torch.no_grad():\n","    logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n","    probs = logits.softmax(dim=-1)\n","\n","fake, real = probs.detach().cpu().flatten().numpy().tolist()\n","\n","print(f\"Real Probability: {real}\\nFake Probability: {fake}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"htH0LX2GzVMe","executionInfo":{"status":"ok","timestamp":1671299687481,"user_tz":300,"elapsed":319,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"51a0dc2f-431a-4c20-9a1a-a968ab69f4e0"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["Real Probability: 0.9610210657119751\n","Fake Probability: 0.0389789454638958\n"]}]},{"cell_type":"code","source":["#Is original\n","device=\"cuda\"\n","query = \"\"\"The decore, the tables, the hostess, the cultural ambiance... all perfect!! But the food was not what I expected. Besides THE BEST Thai tea in town, I've had better Thai food. But overall a good date night location and a good experience.\"\"\"\n","tokens = tokenizer.encode(query,return_tensors=\"pt\")\n","all_tokens = len(tokens[0])\n","mask = torch.ones_like(tokens)\n","\n","with torch.no_grad():\n","    logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n","    probs = logits.softmax(dim=-1)\n","\n","fake, real = probs.detach().cpu().flatten().numpy().tolist()\n","\n","print(f\"Real Probability: {real}\\nFake Probability: {fake}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HYIO5gAAzf42","executionInfo":{"status":"ok","timestamp":1671299691954,"user_tz":300,"elapsed":308,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"939ecdc1-595b-4399-d975-e12bca774f88"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["Real Probability: 0.9932860732078552\n","Fake Probability: 0.006713952403515577\n"]}]},{"cell_type":"code","source":["#Is fake generated by ChatGPT\n","device=\"cuda\"\n","query = \"\"\"\n","The food at this restaurant is absolutely incredible. From the moment we walked in, we were greeted by the friendly staff and the mouthwatering smells coming from the kitchen. The service was top-notch and the presentation of the dishes was stunning. I would highly recommend this restaurant to anyone looking for a high-quality dining experience\n","\"\"\"\n","tokens = tokenizer.encode(query,return_tensors=\"pt\")\n","all_tokens = len(tokens[0])\n","mask = torch.ones_like(tokens)\n","\n","with torch.no_grad():\n","    logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n","    probs = logits.softmax(dim=-1)\n","\n","fake, real = probs.detach().cpu().flatten().numpy().tolist()\n","\n","print(f\"Real Probability: {real}\\nFake Probability: {fake}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h7UmbPRczn0Z","executionInfo":{"status":"ok","timestamp":1671299696281,"user_tz":300,"elapsed":318,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"3ff48a0b-6501-43bd-8da9-23d1efcf8bdb"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["Real Probability: 0.1857033371925354\n","Fake Probability: 0.8142966628074646\n"]}]},{"cell_type":"code","source":["#Is fake generated by ChatGPT\n","device=\"cuda\"\n","query = \"\"\"\n","This restaurant is a hidden gem. The food is always fresh and full of flavor, and the portions are generous. The staff are attentive and friendly, and they always make sure we have everything we need. I would highly recommend this restaurant to anyone looking for a delicious meal at a reasonable price.\n","\"\"\"\n","tokens = tokenizer.encode(query,return_tensors=\"pt\")\n","all_tokens = len(tokens[0])\n","mask = torch.ones_like(tokens)\n","\n","with torch.no_grad():\n","    logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n","    probs = logits.softmax(dim=-1)\n","\n","fake, real = probs.detach().cpu().flatten().numpy().tolist()\n","\n","print(f\"Real Probability: {real}\\nFake Probability: {fake}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RmwaNkKWD7m_","executionInfo":{"status":"ok","timestamp":1671299699217,"user_tz":300,"elapsed":1,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"01bb6e6c-7b9a-4bc0-bf1c-8cc7dd8a0eb7"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["Real Probability: 0.016348792240023613\n","Fake Probability: 0.9836512207984924\n"]}]},{"cell_type":"code","source":["#Is fake generated by ChatGPT\n","device=\"cuda\"\n","query = \"\"\"\n","Terrible service, would not recommend.\"\"\"\n","tokens = tokenizer.encode(query,return_tensors=\"pt\")\n","all_tokens = len(tokens[0])\n","mask = torch.ones_like(tokens)\n","\n","with torch.no_grad():\n","    logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n","    probs = logits.softmax(dim=-1)\n","\n","fake, real = probs.detach().cpu().flatten().numpy().tolist()\n","\n","print(f\"Real Probability: {real}\\nFake Probability: {fake}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4CkZL5v0EW4C","executionInfo":{"status":"ok","timestamp":1671299703476,"user_tz":300,"elapsed":2,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"e3b3b2ed-20c8-4260-af9e-d9e1af92465c"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Real Probability: 0.3199218213558197\n","Fake Probability: 0.6800782084465027\n"]}]},{"cell_type":"code","source":["\n","#Is from the dataset\n","device=\"cuda\"\n","query = \"\"\"\n","best chicken with green and yellow sauce cilantro rice.\n","\"\"\"\n","tokens = tokenizer.encode(query,return_tensors=\"pt\")\n","all_tokens = len(tokens[0])\n","mask = torch.ones_like(tokens)\n","\n","with torch.no_grad():\n","    logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n","    probs = logits.softmax(dim=-1)\n","\n","fake, real = probs.detach().cpu().flatten().numpy().tolist()\n","\n","print(f\"Real Probability: {real}\\nFake Probability: {fake}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SJLy7nAOEM5R","executionInfo":{"status":"ok","timestamp":1671299707496,"user_tz":300,"elapsed":321,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"4a28b364-7a21-41e9-b27c-86313c36def6"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["Real Probability: 0.46642154455184937\n","Fake Probability: 0.5335784554481506\n"]}]},{"cell_type":"code","source":["\n","#I wrote it\n","device=\"cuda\"\n","query = \"\"\"\n","This place has the best sushi I've had in a while. What brought me to this place was the unlimited menu- definitely worth every buck!\n","\"\"\"\n","tokens = tokenizer.encode(query,return_tensors=\"pt\")\n","all_tokens = len(tokens[0])\n","mask = torch.ones_like(tokens)\n","\n","with torch.no_grad():\n","    logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n","    probs = logits.softmax(dim=-1)\n","\n","fake, real = probs.detach().cpu().flatten().numpy().tolist()\n","\n","print(f\"Real Probability: {real}\\nFake Probability: {fake}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O8emoC6ZEdz7","executionInfo":{"status":"ok","timestamp":1671299712501,"user_tz":300,"elapsed":303,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"4c59de43-c1c3-4b0d-b11c-d83066a43fbc"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["Real Probability: 0.9799696803092957\n","Fake Probability: 0.02003030851483345\n"]}]},{"cell_type":"code","execution_count":67,"metadata":{"id":"27XzPoNw5ZU8","executionInfo":{"status":"ok","timestamp":1671299716832,"user_tz":300,"elapsed":306,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["def predict(query, model, tokenizer, device=\"cuda\"):\n","    tokens = tokenizer.encode(query)\n","    all_tokens = len(tokens)\n","    tokens = tokens[:tokenizer.model_max_length - 2]\n","    used_tokens = len(tokens)\n","    tokens = torch.tensor([tokenizer.bos_token_id] + tokens + [tokenizer.eos_token_id]).unsqueeze(0)\n","    mask = torch.ones_like(tokens)\n","\n","    with torch.no_grad():\n","        logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n","        probs = logits.softmax(dim=-1)\n","\n","    fake, real = probs.detach().cpu().flatten().numpy().tolist()\n","    return real"]},{"cell_type":"code","execution_count":68,"metadata":{"id":"ZqR-XqVK5ZU8","outputId":"f5d4b913-4648-4cc9-9dc2-b702d9ab981e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671299719122,"user_tz":300,"elapsed":308,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9970579147338867"]},"metadata":{},"execution_count":68}],"source":["query = \"\"\"I work in the wedding industry and have to work long days, on my feet, outside in the heat, and have to look professional. I've spent a ridiculous amount of money on high end dress shoes like Merrels and just have not been able to find a pair that are comfortable to wear all day. Both for my feet and my back. Enter the Sanuk yoga sling!!! These shoes are amazingly comfortable. Though, I will admit it took a few wears to get used to the feel of the yoga matte bottom. At first, it felt a little \"sticky\" to me, and the fabric part that goes through the toe area was a little thick and took some getting used to. I wore them for a few days before taking them out on a job and I can't get over how comfortable they are. Ii have been wearing these shoes now for 3 months, every work day and I am THRILLED. No more back pain, no more sore feet. I also wear these sometimes during my off time,mans every time I wear them, I get compliments on how cute and comfortable they look. The great thing about these shoes is the yoga matte bottom. It helps your feet grip to the shoe a bit, so your foot can just walk normally, without having to grip the shoe. You may not realize it, but with a lot of Sandals, your foot is having to work to keep the shoe on, changing the way you walk and stand and ultimately causing foot and back pain. Not with these! Also, the soft linen sits comfortably on your skin and breathes nicely in the heat. The only downside is the funky tan lines, which is why I am sure to alternate shoes on my days off, especially if I plan to be outside for most of the day. If it were not for that, I think these might be the only shoes I'd wear all summer. If you are looking for a reasonable priced, comfortable shoe that you can wear and walk in all day.\"\"\"\n","predict(query,model,tokenizer)"]},{"cell_type":"code","execution_count":69,"metadata":{"id":"MjO8LEfL5ZU8","executionInfo":{"status":"ok","timestamp":1671299725062,"user_tz":300,"elapsed":2826,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["preds, preds_probas = [],[]\n","for i, row in valid_dataset.iterrows():\n","    query = row[\"text_\"]\n","    pred = predict(query,model,tokenizer)\n","    preds_probas.append(pred)\n","    if pred >= 0.5:\n","        preds.append(1)\n","    else:\n","        preds.append(0)"]},{"cell_type":"code","execution_count":70,"metadata":{"id":"PAN0Rhni5ZU9","outputId":"642651c6-40d7-49ff-ec41-05c4713a1722","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671299728024,"user_tz":300,"elapsed":406,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[103,   3],\n","       [  8,  95]])"]},"metadata":{},"execution_count":70}],"source":["from sklearn.metrics import confusion_matrix\n","y_true = valid_dataset.target.values\n","y_pred = preds\n","confusion_matrix(y_true,y_pred)"]},{"cell_type":"code","execution_count":71,"metadata":{"id":"zzMVEoLa5ZU9","executionInfo":{"status":"ok","timestamp":1671299730977,"user_tz":300,"elapsed":307,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n","acc = accuracy_score(y_true,y_pred)\n","precision = precision_score(y_true,y_pred)\n","recall = recall_score(y_true,y_pred)"]},{"cell_type":"code","execution_count":72,"metadata":{"id":"FkmcU4j-5ZU9","outputId":"1553facd-9092-4a0a-d16f-a8ac8446b047","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671299732687,"user_tz":300,"elapsed":3,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 94.73684210526315; Precision:96.93877551020408; Recall:92.23300970873787\n"]}],"source":["print(f\"Accuracy: {acc*100}; Precision:{precision*100}; Recall:{recall*100}\")"]},{"cell_type":"code","execution_count":73,"metadata":{"id":"cJNE3J5B5ZU9","outputId":"2c9f3be0-f511-47a9-fcf9-e36d81376fd4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671299735498,"user_tz":300,"elapsed":303,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","          CG       0.93      0.97      0.95       106\n","          OR       0.97      0.92      0.95       103\n","\n","    accuracy                           0.95       209\n","   macro avg       0.95      0.95      0.95       209\n","weighted avg       0.95      0.95      0.95       209\n","\n"]}],"source":["print(classification_report(y_true, y_pred, target_names=[\"CG\",\"OR\"]))"]},{"cell_type":"markdown","metadata":{"id":"0fakNseF5ZU-"},"source":["#### Writing predictions to disc"]},{"cell_type":"code","execution_count":74,"metadata":{"id":"Tq5WjOm25ZU-","executionInfo":{"status":"ok","timestamp":1671299745000,"user_tz":300,"elapsed":304,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["preds_df_rows = []\n","for i, row in valid_dataset.iterrows():\n","    query = row[\"text_\"]\n","    pred_prob = preds_probas[i]\n","    pred_label = preds[i]\n","    preds_df_rows.append([pred_prob,pred_label])\n","preds_df = pd.DataFrame(preds_df_rows, columns=[\"Finetune_Roberta_Model_Probability\",\"Finetune_Roberta_Model_Prediction\"])"]},{"cell_type":"code","execution_count":75,"metadata":{"id":"hDdWRg1d5ZU-","executionInfo":{"status":"ok","timestamp":1671299752497,"user_tz":300,"elapsed":343,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["preds_df.to_csv(\"roberta_predictionsGPT3FineTune2.csv\", index=None)"]},{"cell_type":"code","execution_count":76,"metadata":{"id":"RWArBjVq5ZU-","executionInfo":{"status":"ok","timestamp":1671299755088,"user_tz":300,"elapsed":306,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["%cp /content/roberta_predictionsGPT3FineTune2.csv /content/drive/MyDrive/YelpDataset/Roberta"]},{"cell_type":"markdown","source":["# CHATGPT GENERATED DATA"],"metadata":{"id":"pqSXom_QUFQd"}},{"cell_type":"code","source":["valid_dataset = pd.read_csv(\"/content/ChatGPTGeneratedFakeReviews.csv\")"],"metadata":{"id":"akEXpvKkx4TV","executionInfo":{"status":"ok","timestamp":1671302008153,"user_tz":300,"elapsed":333,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"execution_count":94,"outputs":[]},{"cell_type":"code","source":["valid_dataset.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cAQL7YTaUWI-","executionInfo":{"status":"ok","timestamp":1671302010246,"user_tz":300,"elapsed":323,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"6f842547-c296-4aa2-d495-3931a7c4fe00"},"execution_count":95,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(56, 2)"]},"metadata":{},"execution_count":95}]},{"cell_type":"code","source":[],"metadata":{"id":"dwSSGMV0UXXu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output_model_file = '/content/ft-roberta-yelpreviews_kitchenGPT3Finetuned2.pt'"],"metadata":{"executionInfo":{"status":"ok","timestamp":1671302017494,"user_tz":300,"elapsed":315,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"InFckZHVVvS0"},"execution_count":96,"outputs":[]},{"cell_type":"code","execution_count":97,"metadata":{"executionInfo":{"status":"ok","timestamp":1671302020024,"user_tz":300,"elapsed":674,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"FCg2n3k4VvS1"},"outputs":[],"source":["# model = torch.load('../../data/classification/models/ft-roberta-amazonreviews.pt')\n","model = torch.load(output_model_file)"]},{"cell_type":"code","execution_count":98,"metadata":{"executionInfo":{"status":"ok","timestamp":1671302021124,"user_tz":300,"elapsed":1,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"xm4Fj-czVvS1"},"outputs":[],"source":["def predict(query, model, tokenizer, device=\"cuda\"):\n","    tokens = tokenizer.encode(query)\n","    all_tokens = len(tokens)\n","    tokens = tokens[:tokenizer.model_max_length - 2]\n","    used_tokens = len(tokens)\n","    tokens = torch.tensor([tokenizer.bos_token_id] + tokens + [tokenizer.eos_token_id]).unsqueeze(0)\n","    mask = torch.ones_like(tokens)\n","\n","    with torch.no_grad():\n","        logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n","        probs = logits.softmax(dim=-1)\n","\n","    fake, real = probs.detach().cpu().flatten().numpy().tolist()\n","    return real"]},{"cell_type":"code","execution_count":99,"metadata":{"outputId":"c69ac29d-cbcd-43e7-a47a-a5a529e26ab1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671302023025,"user_tz":300,"elapsed":2,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"-Pf6fIhPVvS1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9970579147338867"]},"metadata":{},"execution_count":99}],"source":["query = \"\"\"I work in the wedding industry and have to work long days, on my feet, outside in the heat, and have to look professional. I've spent a ridiculous amount of money on high end dress shoes like Merrels and just have not been able to find a pair that are comfortable to wear all day. Both for my feet and my back. Enter the Sanuk yoga sling!!! These shoes are amazingly comfortable. Though, I will admit it took a few wears to get used to the feel of the yoga matte bottom. At first, it felt a little \"sticky\" to me, and the fabric part that goes through the toe area was a little thick and took some getting used to. I wore them for a few days before taking them out on a job and I can't get over how comfortable they are. Ii have been wearing these shoes now for 3 months, every work day and I am THRILLED. No more back pain, no more sore feet. I also wear these sometimes during my off time,mans every time I wear them, I get compliments on how cute and comfortable they look. The great thing about these shoes is the yoga matte bottom. It helps your feet grip to the shoe a bit, so your foot can just walk normally, without having to grip the shoe. You may not realize it, but with a lot of Sandals, your foot is having to work to keep the shoe on, changing the way you walk and stand and ultimately causing foot and back pain. Not with these! Also, the soft linen sits comfortably on your skin and breathes nicely in the heat. The only downside is the funky tan lines, which is why I am sure to alternate shoes on my days off, especially if I plan to be outside for most of the day. If it were not for that, I think these might be the only shoes I'd wear all summer. If you are looking for a reasonable priced, comfortable shoe that you can wear and walk in all day.\"\"\"\n","predict(query,model,tokenizer)"]},{"cell_type":"code","execution_count":100,"metadata":{"executionInfo":{"status":"ok","timestamp":1671302025118,"user_tz":300,"elapsed":669,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"wzjK8e64VvS1"},"outputs":[],"source":["preds, preds_probas = [],[]\n","for i, row in valid_dataset.iterrows():\n","    query = row[\"text\"]\n","    pred = predict(query,model,tokenizer)\n","    preds_probas.append(pred)\n","    if pred >= 0.5:\n","        preds.append(1)\n","    else:\n","        preds.append(0)"]},{"cell_type":"code","execution_count":101,"metadata":{"outputId":"7cec8d75-dafa-40d4-e4ca-285090eb47c8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671302027152,"user_tz":300,"elapsed":2,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"VPR-d3vhVvS1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[50,  3],\n","       [ 0,  3]])"]},"metadata":{},"execution_count":101}],"source":["from sklearn.metrics import confusion_matrix\n","y_true = valid_dataset.label.values\n","y_pred = preds\n","confusion_matrix(y_true,y_pred)"]},{"cell_type":"code","execution_count":102,"metadata":{"executionInfo":{"status":"ok","timestamp":1671302028849,"user_tz":300,"elapsed":2,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"uG7oxRkpVvS1"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n","acc = accuracy_score(y_true,y_pred)\n","precision = precision_score(y_true,y_pred)\n","recall = recall_score(y_true,y_pred)"]},{"cell_type":"code","execution_count":103,"metadata":{"outputId":"eb090f0a-c919-4d85-eb8c-988fc4d7fadd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671302031574,"user_tz":300,"elapsed":309,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"IB4NICqKVvS1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 94.64285714285714; Precision:50.0; Recall:100.0\n"]}],"source":["print(f\"Accuracy: {acc*100}; Precision:{precision*100}; Recall:{recall*100}\")"]},{"cell_type":"code","execution_count":104,"metadata":{"outputId":"59fff555-bf84-4b8f-ae67-fe144db8c025","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671302035171,"user_tz":300,"elapsed":307,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"8RN0CTbmVvS2"},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","          CG       1.00      0.94      0.97        53\n","          OR       0.50      1.00      0.67         3\n","\n","    accuracy                           0.95        56\n","   macro avg       0.75      0.97      0.82        56\n","weighted avg       0.97      0.95      0.95        56\n","\n"]}],"source":["print(classification_report(y_true, y_pred, target_names=[\"CG\",\"OR\"]))"]},{"cell_type":"code","source":["%cp /content/ChatGPTGeneratedFakeReviews.csv /content/drive/MyDrive/YelpDataset/Roberta"],"metadata":{"id":"Dzpswa8FXbBG","executionInfo":{"status":"ok","timestamp":1671302078348,"user_tz":300,"elapsed":317,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"execution_count":105,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1Rik5HsnOXUaNZJ78kpQoZz_0w_DFcHH_","timestamp":1671227924459},{"file_id":"1hXEJRaZUcnmInrho8vgk5o_P0slXyilC","timestamp":1670518287823},{"file_id":"https://github.com/waterfield-95/FakeReviews/blob/main/nbs/classification/2_roberta_finetune_amazon_reviews.ipynb","timestamp":1669834579302}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"bc71df8cfb87440c92129db5b22f910d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_30f45a597635486cbfaa6d585c40e758","IPY_MODEL_993aa808bc2f4dd08d65df45693838e6","IPY_MODEL_6747ad0f8359439cb0b4331a1156b3df"],"layout":"IPY_MODEL_a0f0597dd3514c3d87af73707a1762a6"}},"30f45a597635486cbfaa6d585c40e758":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8e976ed82504353a909161e2587329f","placeholder":"​","style":"IPY_MODEL_cbbeb7a94fdf4a01a6d4aaa2c9b6e2ed","value":"Downloading: 100%"}},"993aa808bc2f4dd08d65df45693838e6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_46984893dcbf40cabcba3bdf5084e734","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ea4a8f6de8004342ab2a81d5e6e6347e","value":898823}},"6747ad0f8359439cb0b4331a1156b3df":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f73af6f92a1467a824b0d1335d0833a","placeholder":"​","style":"IPY_MODEL_5cc2200fe6da402fbb37627d5232ad4d","value":" 899k/899k [00:01&lt;00:00, 889kB/s]"}},"a0f0597dd3514c3d87af73707a1762a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8e976ed82504353a909161e2587329f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbbeb7a94fdf4a01a6d4aaa2c9b6e2ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46984893dcbf40cabcba3bdf5084e734":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea4a8f6de8004342ab2a81d5e6e6347e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3f73af6f92a1467a824b0d1335d0833a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cc2200fe6da402fbb37627d5232ad4d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb0f96e3bd80463e9388281c4d5fb9d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_39b2ff06312e4a4cbd81009e999fc274","IPY_MODEL_28850980c79e4485b8fb6794b8380658","IPY_MODEL_422a259495eb4384939119bab6bac7af"],"layout":"IPY_MODEL_5ac7148e84c74512a730f4b96c328807"}},"39b2ff06312e4a4cbd81009e999fc274":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_122e22163da24ecbabe9893643a0d647","placeholder":"​","style":"IPY_MODEL_820489357dd94b5bb503007086c1c16f","value":"Downloading: 100%"}},"28850980c79e4485b8fb6794b8380658":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_275848407b5e44969bb909acd4671d80","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf5a9cbd92ef405188cedf7d98fdd37c","value":456318}},"422a259495eb4384939119bab6bac7af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e6b796efef94c8ca594f8dcf2bd4ffe","placeholder":"​","style":"IPY_MODEL_a03201986de5467db25728c363972482","value":" 456k/456k [00:01&lt;00:00, 512kB/s]"}},"5ac7148e84c74512a730f4b96c328807":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"122e22163da24ecbabe9893643a0d647":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"820489357dd94b5bb503007086c1c16f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"275848407b5e44969bb909acd4671d80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf5a9cbd92ef405188cedf7d98fdd37c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0e6b796efef94c8ca594f8dcf2bd4ffe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a03201986de5467db25728c363972482":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72c672cfe00143529fc6511a58a2533b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_674526a8676a4fa8b772c84cffb067af","IPY_MODEL_24dc5e4511054a8595de957d995a1b7e","IPY_MODEL_652a7e3ce8ba4161ae41d1f3b663a734"],"layout":"IPY_MODEL_86c0104f571949f0b448818af9d6b61f"}},"674526a8676a4fa8b772c84cffb067af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_11150fe4d84340668d341f3365c2b867","placeholder":"​","style":"IPY_MODEL_6670dfadbb734cecb2bdf61a6a723754","value":"Downloading: 100%"}},"24dc5e4511054a8595de957d995a1b7e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9e244d317694dc3886c81e89cdd72f0","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d1609fc5354f47c59af870f3eb3b259a","value":481}},"652a7e3ce8ba4161ae41d1f3b663a734":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_889e2e58d7b54feeb5f9bb4635150311","placeholder":"​","style":"IPY_MODEL_8b6654632d0c47e6923628a2f4b5bed9","value":" 481/481 [00:00&lt;00:00, 30.4kB/s]"}},"86c0104f571949f0b448818af9d6b61f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11150fe4d84340668d341f3365c2b867":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6670dfadbb734cecb2bdf61a6a723754":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9e244d317694dc3886c81e89cdd72f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1609fc5354f47c59af870f3eb3b259a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"889e2e58d7b54feeb5f9bb4635150311":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b6654632d0c47e6923628a2f4b5bed9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}