{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1kKKVp-sXTSGV6WPP-ndiYym0JZHMAJ8T","timestamp":1670739337707}],"authorship_tag":"ABX9TyPmTF2cS7UGA9vmItqRD5wH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Comparison between the finetuned GPT2 and GPT3 models on the Yelp's Restaurant Category"],"metadata":{"id":"ptAwlyiNTfmk"}},{"cell_type":"code","source":["!pip3 install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n","!pip install transformers\n","!pip install fastai==2.2.7"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v-XhKuazT7dT","executionInfo":{"status":"ok","timestamp":1670739540003,"user_tz":300,"elapsed":171591,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"382ce241-e53a-4f38-a75f-bafd5d6b21ad"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.7.1+cu110\n","  Downloading https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp38-cp38-linux_x86_64.whl (1156.8 MB)\n","\u001b[K     |███████████████████████         | 834.1 MB 1.2 MB/s eta 0:04:37tcmalloc: large alloc 1147494400 bytes == 0x38eac000 @  0x7fe89f64e615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n","\u001b[K     |█████████████████████████████▏  | 1055.7 MB 1.1 MB/s eta 0:01:32tcmalloc: large alloc 1434370048 bytes == 0x7d502000 @  0x7fe89f64e615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n","\u001b[K     |████████████████████████████████| 1156.8 MB 1.1 MB/s eta 0:00:01tcmalloc: large alloc 1445961728 bytes == 0xd2cee000 @  0x7fe89f64e615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91 0x5d8941 0x4fe318\n","\u001b[K     |████████████████████████████████| 1156.8 MB 14 kB/s \n","\u001b[?25hCollecting torchvision==0.8.2+cu110\n","  Downloading https://download.pytorch.org/whl/cu110/torchvision-0.8.2%2Bcu110-cp38-cp38-linux_x86_64.whl (12.9 MB)\n","\u001b[K     |████████████████████████████████| 12.9 MB 31.8 MB/s \n","\u001b[?25hCollecting torchaudio==0.7.2\n","  Downloading torchaudio-0.7.2-cp38-cp38-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 17.4 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.7.1+cu110) (4.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.7.1+cu110) (1.21.6)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.8.2+cu110) (7.1.2)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.13.0+cu116\n","    Uninstalling torch-1.13.0+cu116:\n","      Successfully uninstalled torch-1.13.0+cu116\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.14.0+cu116\n","    Uninstalling torchvision-0.14.0+cu116:\n","      Successfully uninstalled torchvision-0.14.0+cu116\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.13.0+cu116\n","    Uninstalling torchaudio-0.13.0+cu116:\n","      Successfully uninstalled torchaudio-0.13.0+cu116\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.7.1+cu110 which is incompatible.\u001b[0m\n","Successfully installed torch-1.7.1+cu110 torchaudio-0.7.2 torchvision-0.8.2+cu110\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 29.0 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 69.5 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 79.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fastai==2.2.7\n","  Downloading fastai-2.2.7-py3-none-any.whl (193 kB)\n","\u001b[K     |████████████████████████████████| 193 kB 32.6 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from fastai==2.2.7) (1.3.5)\n","Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (from fastai==2.2.7) (21.1.3)\n","Requirement already satisfied: pillow>6.0.0 in /usr/local/lib/python3.8/dist-packages (from fastai==2.2.7) (7.1.2)\n","Collecting spacy<3\n","  Downloading spacy-2.3.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.0 MB)\n","\u001b[K     |████████████████████████████████| 5.0 MB 75.2 MB/s \n","\u001b[?25hRequirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.8/dist-packages (from fastai==2.2.7) (1.0.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from fastai==2.2.7) (1.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from fastai==2.2.7) (21.3)\n","Requirement already satisfied: torchvision<0.9,>=0.8 in /usr/local/lib/python3.8/dist-packages (from fastai==2.2.7) (0.8.2+cu110)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from fastai==2.2.7) (1.7.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from fastai==2.2.7) (3.2.2)\n","Requirement already satisfied: torch<1.8,>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from fastai==2.2.7) (1.7.1+cu110)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from fastai==2.2.7) (6.0)\n","Collecting fastcore<1.4,>=1.3.8\n","  Downloading fastcore-1.3.29-py3-none-any.whl (55 kB)\n","\u001b[K     |████████████████████████████████| 55 kB 4.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fastai==2.2.7) (2.23.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3->fastai==2.2.7) (57.4.0)\n","Collecting plac<1.2.0,>=0.9.6\n","  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3->fastai==2.2.7) (4.64.1)\n","Collecting srsly<1.1.0,>=1.0.2\n","  Downloading srsly-1.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n","\u001b[K     |████████████████████████████████| 211 kB 80.5 MB/s \n","\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3->fastai==2.2.7) (1.0.9)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3->fastai==2.2.7) (1.21.6)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3->fastai==2.2.7) (0.10.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3->fastai==2.2.7) (2.0.7)\n","Collecting thinc<7.5.0,>=7.4.1\n","  Downloading thinc-7.4.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 62.5 MB/s \n","\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3->fastai==2.2.7) (3.0.8)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3->fastai==2.2.7) (0.7.9)\n","Collecting catalogue<1.1.0,>=0.0.7\n","  Downloading catalogue-1.0.2-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fastai==2.2.7) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fastai==2.2.7) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fastai==2.2.7) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->fastai==2.2.7) (2.10)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch<1.8,>=1.7.0->fastai==2.2.7) (4.4.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->fastai==2.2.7) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->fastai==2.2.7) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->fastai==2.2.7) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->fastai==2.2.7) (0.11.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->fastai==2.2.7) (1.15.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->fastai==2.2.7) (2022.6)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->fastai==2.2.7) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->fastai==2.2.7) (3.1.0)\n","Installing collected packages: srsly, plac, catalogue, thinc, spacy, fastcore, fastai\n","  Attempting uninstall: srsly\n","    Found existing installation: srsly 2.4.5\n","    Uninstalling srsly-2.4.5:\n","      Successfully uninstalled srsly-2.4.5\n","  Attempting uninstall: catalogue\n","    Found existing installation: catalogue 2.0.8\n","    Uninstalling catalogue-2.0.8:\n","      Successfully uninstalled catalogue-2.0.8\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 8.1.5\n","    Uninstalling thinc-8.1.5:\n","      Successfully uninstalled thinc-8.1.5\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 3.4.3\n","    Uninstalling spacy-3.4.3:\n","      Successfully uninstalled spacy-3.4.3\n","  Attempting uninstall: fastcore\n","    Found existing installation: fastcore 1.5.27\n","    Uninstalling fastcore-1.5.27:\n","      Successfully uninstalled fastcore-1.5.27\n","  Attempting uninstall: fastai\n","    Found existing installation: fastai 2.7.10\n","    Uninstalling fastai-2.7.10:\n","      Successfully uninstalled fastai-2.7.10\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 2.3.8 which is incompatible.\n","confection 0.0.3 requires srsly<3.0.0,>=2.4.0, but you have srsly 1.0.6 which is incompatible.\u001b[0m\n","Successfully installed catalogue-1.0.2 fastai-2.2.7 fastcore-1.3.29 plac-1.1.3 spacy-2.3.8 srsly-1.0.6 thinc-7.4.6\n"]}]},{"cell_type":"code","source":["import torch\n","from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n","from fastai.text.all import *\n","import gc"],"metadata":{"id":"-HO6vQ0-T7bC","executionInfo":{"status":"ok","timestamp":1670739556983,"user_tz":300,"elapsed":14645,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["print(torch. __version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f2LKGKdaT7YK","executionInfo":{"status":"ok","timestamp":1670739556984,"user_tz":300,"elapsed":10,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"d3d5f0af-79ae-4643-af28-ff3222002e64"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["1.7.1+cu110\n"]}]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D9jzLzxVW6W9","executionInfo":{"status":"ok","timestamp":1670739707541,"user_tz":300,"elapsed":25940,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"ec42f683-ebf7-4c0f-d5cc-ff8e3f68eae6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["The sample data with 100 datapoints from the Yelp Dataset is at: ```/content/drive/MyDrive/YelpDataset/GPT3/DataForGPT3_prepared.jsonl```"],"metadata":{"id":"J7Cht8XXXQXA"}},{"cell_type":"code","source":["!pip install --upgrade openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y0xMHXJSXr_F","executionInfo":{"status":"ok","timestamp":1670739572890,"user_tz":300,"elapsed":15910,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"9674ec3a-56f9-483a-c4b0-0090f2e5900a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting openai\n","  Downloading openai-0.25.0.tar.gz (44 kB)\n","\u001b[K     |████████████████████████████████| 44 kB 2.3 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.8/dist-packages (from openai) (3.0.10)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai) (1.21.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from openai) (4.4.0)\n","Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from openai) (1.3.5)\n","Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.23.0)\n","Collecting pandas-stubs>=1.1.0.11\n","  Downloading pandas_stubs-1.5.2.221124-py3-none-any.whl (146 kB)\n","\u001b[K     |████████████████████████████████| 146 kB 29.8 MB/s \n","\u001b[?25hRequirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n","Collecting types-pytz>=2022.1.1\n","  Downloading types_pytz-2022.6.0.1-py3-none-any.whl (4.7 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n","Building wheels for collected packages: openai\n","  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai: filename=openai-0.25.0-py3-none-any.whl size=55880 sha256=69e219f5e87149c5c4293b22098b25f497161141ba681bf7076c165456d7a52d\n","  Stored in directory: /root/.cache/pip/wheels/4b/92/33/6f57c7aae0b16875267999a50570e81f15eecec577ebe05a2e\n","Successfully built openai\n","Installing collected packages: types-pytz, pandas-stubs, openai\n","Successfully installed openai-0.25.0 pandas-stubs-1.5.2.221124 types-pytz-2022.6.0.1\n"]}]},{"cell_type":"code","source":["import openai\n","openai.api_key = \"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\""],"metadata":{"id":"9jwGhuwlbb5O","executionInfo":{"status":"ok","timestamp":1670739573379,"user_tz":300,"elapsed":3,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#Let's check out the ADA finetuned model from last time:\n","!openai -k \"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\" api fine_tunes.list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U-OjkD4aXFvO","executionInfo":{"status":"ok","timestamp":1670739575780,"user_tz":300,"elapsed":1274,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"363255af-a04b-4825-9b98-32610b23f9c4"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"data\": [\n","    {\n","      \"created_at\": 1670396255,\n","      \"fine_tuned_model\": \"ada:ft-new-york-university-2022-12-07-06-58-34\",\n","      \"hyperparams\": {\n","        \"batch_size\": 1,\n","        \"learning_rate_multiplier\": 0.1,\n","        \"n_epochs\": 1,\n","        \"prompt_loss_weight\": 0.01\n","      },\n","      \"id\": \"ft-thRZbmgrRzU1HkLYQDEaFvyr\",\n","      \"model\": \"ada\",\n","      \"object\": \"fine-tune\",\n","      \"organization_id\": \"org-xW0Dhs9vleFDuwl6YbhZdKPz\",\n","      \"result_files\": [\n","        {\n","          \"bytes\": 5168,\n","          \"created_at\": 1670396315,\n","          \"filename\": \"compiled_results.csv\",\n","          \"id\": \"file-IFdzZTA8YAPuRl3AseUdPLPg\",\n","          \"object\": \"file\",\n","          \"purpose\": \"fine-tune-results\",\n","          \"status\": \"processed\",\n","          \"status_details\": null\n","        }\n","      ],\n","      \"status\": \"succeeded\",\n","      \"training_files\": [\n","        {\n","          \"bytes\": 36459,\n","          \"created_at\": 1670396255,\n","          \"filename\": \"/content/DataForGPT3_prepared.jsonl\",\n","          \"id\": \"file-xtiaVssGfpeXQktXxq2msDEt\",\n","          \"object\": \"file\",\n","          \"purpose\": \"fine-tune\",\n","          \"status\": \"processed\",\n","          \"status_details\": null\n","        }\n","      ],\n","      \"updated_at\": 1670396315,\n","      \"validation_files\": []\n","    },\n","    {\n","      \"created_at\": 1670711862,\n","      \"fine_tuned_model\": \"ada:ft-new-york-university-2022-12-11-04-47-21\",\n","      \"hyperparams\": {\n","        \"batch_size\": 4,\n","        \"learning_rate_multiplier\": 0.1,\n","        \"n_epochs\": 1,\n","        \"prompt_loss_weight\": 0.01\n","      },\n","      \"id\": \"ft-84QwoJBS3MJbpd9PFnYt3eDr\",\n","      \"model\": \"ada\",\n","      \"object\": \"fine-tune\",\n","      \"organization_id\": \"org-xW0Dhs9vleFDuwl6YbhZdKPz\",\n","      \"result_files\": [\n","        {\n","          \"bytes\": 16069,\n","          \"created_at\": 1670734042,\n","          \"filename\": \"compiled_results.csv\",\n","          \"id\": \"file-XXLTj7ZW2f0olC41xyQi6k85\",\n","          \"object\": \"file\",\n","          \"purpose\": \"fine-tune-results\",\n","          \"status\": \"processed\",\n","          \"status_details\": null\n","        }\n","      ],\n","      \"status\": \"succeeded\",\n","      \"training_files\": [\n","        {\n","          \"bytes\": 480581,\n","          \"created_at\": 1670711860,\n","          \"filename\": \"TrainDataForGPT3_prepared.jsonl\",\n","          \"id\": \"file-3zemrsmbQTwYfsYwSs7XIbuC\",\n","          \"object\": \"file\",\n","          \"purpose\": \"fine-tune\",\n","          \"status\": \"processed\",\n","          \"status_details\": null\n","        }\n","      ],\n","      \"updated_at\": 1670734042,\n","      \"validation_files\": [\n","        {\n","          \"bytes\": 250548,\n","          \"created_at\": 1670711862,\n","          \"filename\": \"ValDataForGPT3_prepared.jsonl\",\n","          \"id\": \"file-ORPbIgPZyHDqqGd2INdkxUkL\",\n","          \"object\": \"file\",\n","          \"purpose\": \"fine-tune\",\n","          \"status\": \"processed\",\n","          \"status_details\": null\n","        }\n","      ]\n","    },\n","    {\n","      \"created_at\": 1670717742,\n","      \"fine_tuned_model\": null,\n","      \"hyperparams\": {\n","        \"batch_size\": 4,\n","        \"learning_rate_multiplier\": null,\n","        \"n_epochs\": 1,\n","        \"prompt_loss_weight\": 0.01\n","      },\n","      \"id\": \"ft-fcbCsWYblUKjgpV2OWPoOyuI\",\n","      \"model\": \"ada\",\n","      \"object\": \"fine-tune\",\n","      \"organization_id\": \"org-xW0Dhs9vleFDuwl6YbhZdKPz\",\n","      \"result_files\": [],\n","      \"status\": \"failed\",\n","      \"training_files\": [\n","        {\n","          \"bytes\": 2419945,\n","          \"created_at\": 1670717741,\n","          \"filename\": \"TrainDataForGPT3_prepared.jsonl\",\n","          \"id\": \"file-RVkjGnhNUgQqIf3XoOjjRRFk\",\n","          \"object\": \"file\",\n","          \"purpose\": \"fine-tune\",\n","          \"status\": \"processed\",\n","          \"status_details\": null\n","        }\n","      ],\n","      \"updated_at\": 1670717907,\n","      \"validation_files\": [\n","        {\n","          \"bytes\": 266841,\n","          \"created_at\": 1670717742,\n","          \"filename\": \"ValDataForGPT3_prepared.jsonl\",\n","          \"id\": \"file-wVVeQ6aQGMESOqcJOCiZECro\",\n","          \"object\": \"file\",\n","          \"purpose\": \"fine-tune\",\n","          \"status\": \"processed\",\n","          \"status_details\": null\n","        }\n","      ]\n","    },\n","    {\n","      \"created_at\": 1670737455,\n","      \"fine_tuned_model\": \"ada:ft-new-york-university-2022-12-11-05-52-26\",\n","      \"hyperparams\": {\n","        \"batch_size\": 4,\n","        \"learning_rate_multiplier\": 0.1,\n","        \"n_epochs\": 1,\n","        \"prompt_loss_weight\": 0.01\n","      },\n","      \"id\": \"ft-IKqQ7Vg6UWtOqRHyADodHnoQ\",\n","      \"model\": \"ada\",\n","      \"object\": \"fine-tune\",\n","      \"organization_id\": \"org-xW0Dhs9vleFDuwl6YbhZdKPz\",\n","      \"result_files\": [\n","        {\n","          \"bytes\": 80786,\n","          \"created_at\": 1670737946,\n","          \"filename\": \"compiled_results.csv\",\n","          \"id\": \"file-xwx2BO8ZrDAU1KNtttbtRLjp\",\n","          \"object\": \"file\",\n","          \"purpose\": \"fine-tune-results\",\n","          \"status\": \"processed\",\n","          \"status_details\": null\n","        }\n","      ],\n","      \"status\": \"succeeded\",\n","      \"training_files\": [\n","        {\n","          \"bytes\": 2419945,\n","          \"created_at\": 1670737454,\n","          \"filename\": \"TrainDataForGPT3_prepared5k.jsonl\",\n","          \"id\": \"file-kiQVKb6YIIQe7ZRmmNEmGlro\",\n","          \"object\": \"file\",\n","          \"purpose\": \"fine-tune\",\n","          \"status\": \"processed\",\n","          \"status_details\": null\n","        }\n","      ],\n","      \"updated_at\": 1670737947,\n","      \"validation_files\": [\n","        {\n","          \"bytes\": 266841,\n","          \"created_at\": 1670737455,\n","          \"filename\": \"ValDataForGPT3_prepared5k.jsonl\",\n","          \"id\": \"file-ZZNICoKhrZt0M4aRak9E5dO6\",\n","          \"object\": \"file\",\n","          \"purpose\": \"fine-tune\",\n","          \"status\": \"processed\",\n","          \"status_details\": null\n","        }\n","      ]\n","    }\n","  ],\n","  \"object\": \"list\"\n","}\n"]}]},{"cell_type":"markdown","source":["As can be seen, our previous finetuned model `ada:ft-new-york-university-2022-12-07-06-58-34` had following hyperparameters:\n","```\n","\"batch_size\": 4,\n","\"learning_rate_multiplier\": 0.1,\n","\"n_epochs\": 1,\n","\"prompt_loss_weight\": 0.01\n","```"],"metadata":{"id":"vGz-3qgBX1fU"}},{"cell_type":"code","source":["!ls /content/drive/MyDrive/YelpDataset/models"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wi3Hy-BrTyOT","executionInfo":{"status":"ok","timestamp":1670715710527,"user_tz":300,"elapsed":641,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"23e585ca-ac36-454f-ddcc-dfcced50fdeb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["gpt2-finetuned-yelp-reviews-sample-1cycle-Automotive.pth\n","gpt2-finetuned-yelp-reviews-sample-1cycle-BeautySpa.pth\n","gpt2-finetuned-yelp-reviews-sample-1cycle-Food.pth\n","gpt2-finetuned-yelp-reviews-sample-1cycle-HomeServices.pth\n","gpt2-finetuned-yelp-reviews-sample-1cycle-Restaurants.pth\n","gpt2-finetuned-yelp-reviews-sample-1cycle-Shopping.pth\n"]}]},{"cell_type":"code","source":["%cp /content/drive/MyDrive/YelpDataset/models/gpt2-finetuned-yelp-reviews-sample-1cycle-Restaurants.pth /content/"],"metadata":{"id":"2TLUtcK8UY4k","executionInfo":{"status":"ok","timestamp":1670739726382,"user_tz":300,"elapsed":18846,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["%mkdir models\n","%mv /content/gpt2-finetuned-yelp-reviews-sample-1cycle-Restaurants.pth /content/models"],"metadata":{"id":"c2XrsNHoVNvv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670739726765,"user_tz":300,"elapsed":404,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"d5c6a7d7-e910-4e69-88f6-ab5a6b918dd0"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘models’: File exists\n"]}]},{"cell_type":"code","source":["class DropOutput(Callback):\n","    def after_pred(self): self.learn.pred = self.pred[0]"],"metadata":{"id":"b3bPmnM8V59k","executionInfo":{"status":"ok","timestamp":1670739617092,"user_tz":300,"elapsed":364,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#Let's now load the gpt-2 finetuned model\n","pretrained_weights = 'gpt2'\n","tokenizer = GPT2TokenizerFast.from_pretrained(pretrained_weights)\n","model = GPT2LMHeadModel.from_pretrained(pretrained_weights)\n","learn = Learner(dls=None, model=model, loss_func=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=Perplexity()).to_fp16()\n","learn.load(\"gpt2-finetuned-yelp-reviews-sample-1cycle-Restaurants\").cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N4TJlKWPXFsN","executionInfo":{"status":"ok","timestamp":1670739760843,"user_tz":300,"elapsed":21594,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"b486796d-5672-4869-d83d-b4ce3ab912bb"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(50257, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",")"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["## Comparisons\n","\n","The GPT-2 model was finetuned on the Restaurant category in the following way:\n","*   Sample Size: 188688\n","*   Batch Size: 4\n","*   Epochs: 1\n","*   Learning Rate: 1e-4\n","*   Train Loss: 3.306005\n","*   Time: 1:20:41\n","\n","The GPT-3 model was finetuned on the Restaurant category in the following way:\n","*   Sample Size: 5500\n","*   Batch Size: 4\n","*   Epochs: 1\n","*   Learning Rate: 0.1 or default by OpenAI\n","*   Time: 00:10:00\n","\n","\n","\n"],"metadata":{"id":"-yr4DbwaWlVd"}},{"cell_type":"markdown","source":["#### Example 1"],"metadata":{"id":"fYVwXMWucxTs"}},{"cell_type":"code","execution_count":42,"metadata":{"id":"xoV9CUmK7dHN","executionInfo":{"status":"ok","timestamp":1670739930534,"user_tz":300,"elapsed":412,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["NUM_OF_SAMPLES = 4\n","prompt = \"Not satisfied with the food\""]},{"cell_type":"markdown","source":["GPT 2"],"metadata":{"id":"QttF-fQlY8Js"}},{"cell_type":"code","execution_count":43,"metadata":{"id":"mYQuA76b7dHN","outputId":"eb91b721-5408-4c4a-94bb-fa092dc0b242","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670739931525,"user_tz":300,"elapsed":2,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 5])"]},"metadata":{},"execution_count":43}],"source":["prompt_ids = tokenizer.encode(prompt)\n","inp = tensor(prompt_ids)[None].cuda()\n","inp.shape"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"EHUykIEK7dHO","outputId":"71d4b10a-fb4b-4c7b-b9b2-daf6c5d02750","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670739933654,"user_tz":300,"elapsed":1131,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]}],"source":["preds = learn.model.generate(inp, max_length=50, do_sample=True, top_k=0, top_p=0.92, num_return_sequences=NUM_OF_SAMPLES, temperature=0.7)"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"dmYoxvEx7dHO","outputId":"730eb5b7-be8f-4137-ae06-1a2a0393d6aa","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1670739933655,"user_tz":300,"elapsed":6,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Not satisfied with the food. I got the calamari which was a little bland. I would give the calamari 3 stars. But the calamari was cooked very well. I would not recommend this place.The service was ok.  The food'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":45}],"source":["tokenizer.decode(preds[0].cpu().numpy())"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"jaA4mG8I7dHO","outputId":"c121f4d6-c155-498f-9f86-e0e20afc94fc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670739934856,"user_tz":300,"elapsed":2,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["0: Not satisfied with the food. I got the calamari which was a little bland. I would give the calamari 3 stars. But the calamari was cooked very well. I would not recommend this place.The service was ok.  The food\n","1: Not satisfied with the food and service.  We had the fried calamari and the scallops.  The calamari was very bland.  The scallops were overcooked.  The calamari was not a good quality.  The\n","2: Not satisfied with the food here. The crab cake was way too salty. The fries were good, but nothing special. The service was good.I love their gumbo. I had the pho dumplings and they were delicious. I also\n","3: Not satisfied with the food. \n","The shrimp and grits were good, but not as good as the crab and shrimp. \n","The fried chicken was also not as good as the shrimp. \n","\n","The atmosphere is not very friendly.\n"]}],"source":["for i, pred in enumerate(preds):\n","  print(\"{}: {}\".format(i, tokenizer.decode(pred, skip_special_tokens=True)))"]},{"cell_type":"markdown","source":["GPT3"],"metadata":{"id":"cKt0CydibQ1z"}},{"cell_type":"code","source":["pred = openai.Completion.create(\n","  model=\"ada:ft-new-york-university-2022-12-11-05-52-26\",\n","  prompt=prompt,\n","  max_tokens=50, n=NUM_OF_SAMPLES, temperature=0.7, top_p=0.92\n",")"],"metadata":{"id":"BukUEgMX0FDk","executionInfo":{"status":"ok","timestamp":1670739943632,"user_tz":300,"elapsed":1837,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["for i in range(NUM_OF_SAMPLES):\n","  print(f\"Sample {i+1}: \")\n","  print(prompt + pred.choices[i].text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FAt7W7p9kwWm","executionInfo":{"status":"ok","timestamp":1670739945657,"user_tz":300,"elapsed":331,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"b4ef920b-466f-4079-9570-3715e4537cff"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample 1: \n","Not satisfied with the food, different flavors.\n","\n","Not a place I would recommend.  \n","\n","I ordered the veggie platter of shrimp, chicken and shrimp.  They gave me a knife and fork to cut my shrimp but they were no longer cutting the\n","Sample 2: \n","Not satisfied with the food quality and service.  We had a party of 4 and was not treated as though we were one meal.  The servers came to our table to thank us for ordering and take our checks.  We waited 45 minutes and the food was still not\n","Sample 3: \n","Not satisfied with the food. We had the chicken and waffles and they were very good, but the bread was really soggy and the eggs were undercooked. I wouldn't return. ENDLESS COMPLAININGS ENDLESS COMPLAININGS ENDLESS COMPL\n","Sample 4: \n","Not satisfied with the food at this place. I just ordered the seafood sandwich and it tasted like some of the other items I've had there. The best part of the experience was the staff. They were very friendly and helpful. \n","\n","I would recommend this place to\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"HQOV-Eorcum6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Example 2"],"metadata":{"id":"42dIrt8Gc1DF"}},{"cell_type":"code","execution_count":49,"metadata":{"id":"g-vw8ukIc1DF","executionInfo":{"status":"ok","timestamp":1670739950948,"user_tz":300,"elapsed":446,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["NUM_OF_SAMPLES = 4\n","prompt = \"The sushi was stale\""]},{"cell_type":"markdown","source":["GPT 2"],"metadata":{"id":"toFvIuCxc1DG"}},{"cell_type":"code","execution_count":50,"metadata":{"outputId":"54778853-1c1e-4e4f-d61a-1d94339e1ac1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670739951614,"user_tz":300,"elapsed":2,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"5SYjGL4Wc1DG"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 4])"]},"metadata":{},"execution_count":50}],"source":["prompt_ids = tokenizer.encode(prompt)\n","inp = tensor(prompt_ids)[None].cuda()\n","inp.shape"]},{"cell_type":"code","execution_count":51,"metadata":{"outputId":"96fda4a8-65b5-4295-81b1-d27e9b443f67","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670739954073,"user_tz":300,"elapsed":1147,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"vf-flk49c1DJ"},"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]}],"source":["preds = learn.model.generate(inp, max_length=50, do_sample=True, top_k=0, top_p=0.92, num_return_sequences=NUM_OF_SAMPLES, temperature=0.7)"]},{"cell_type":"code","execution_count":52,"metadata":{"outputId":"1ee4f967-9075-43fb-d226-7af78e0375a1","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1670739954074,"user_tz":300,"elapsed":5,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"2lgqNfh8c1DJ"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The sushi was stale, the rolls were dry, and the service was horrible. The server was rude and the sushi was cold. I will never go back. The service was great, but the food was not worth the price. I would not recommend'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":52}],"source":["tokenizer.decode(preds[0].cpu().numpy())"]},{"cell_type":"code","execution_count":53,"metadata":{"outputId":"594069e8-860b-4b71-f47f-85b658e3babd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670739956054,"user_tz":300,"elapsed":3,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"X9QSsBu0c1DK"},"outputs":[{"output_type":"stream","name":"stdout","text":["0: The sushi was stale, the rolls were dry, and the service was horrible. The server was rude and the sushi was cold. I will never go back. The service was great, but the food was not worth the price. I would not recommend\n","1: The sushi was stale and the pork belly was dry. The service was great and the wait staff was extremely friendly. The food was good but not great. I would go back.I've been going here since I was a kid and it's pretty\n","2: The sushi was stale and the pork was chewy and tasteless. It was a shame.\n","\n","The service was good. \n","\n","Only thing was a little more attentive than I expected, but the food was good. \n","\n","Only\n","3: The sushi was stale, too much rice and just the right amount of oil. I don't know why the rolls were so stale, but I didn't care for the taste of the fish. The rolls were so fresh I couldn't even finish them\n"]}],"source":["for i, pred in enumerate(preds):\n","  print(\"{}: {}\".format(i, tokenizer.decode(pred, skip_special_tokens=True)))"]},{"cell_type":"markdown","source":["GPT3"],"metadata":{"id":"tf1Yf4udc1DK"}},{"cell_type":"code","source":["pred = openai.Completion.create(\n","  model=\"ada:ft-new-york-university-2022-12-11-05-52-26\",\n","  prompt=prompt,\n","  max_tokens=50, n=NUM_OF_SAMPLES, temperature=0.7, top_p=0.92\n",")"],"metadata":{"id":"9TXuxtVlc1DK","executionInfo":{"status":"ok","timestamp":1670739963627,"user_tz":300,"elapsed":903,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["for i in range(NUM_OF_SAMPLES):\n","  print(f\"Sample {i+1}: \")\n","  print(prompt + pred.choices[i].text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670739964315,"user_tz":300,"elapsed":2,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"c926c915-52ea-498e-c9ef-86b92d244159","id":"tvhZpCj1c1DK"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample 1: \n","The sushi was stale, but it was the service that was awful. They asked us to wait for our food and then refused to bring us food when it was ready. It was a very long wait. The restaurant was very busy and it was almost impossible to get our\n","Sample 2: \n","The sushi was stale and the rice was brown and not fresh. I ordered the crab cakes, which were very salty and the salmon was overcooked. The staff were nice and accommodating. The lady at the counter was kind and helpful. The chef is a student at a\n","Sample 3: \n","The sushi was stale and the wasabi mayo is strong. The tuna was good but the salmon was boring and bland. The service was quick and the drinks were good. The food was bland and bad. END. END END END END END END END END END END\n","Sample 4: \n","The sushi was stale, the nigiri was cold, the sashimi was cold, the miso ramen was warm. The service was average to bad.\n","\n","I will not return.\n","\n","Overall, the food is average, the service is average,\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"h3Dk_XaCdAma"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Example 3: Garlic Bread"],"metadata":{"id":"8JohuutFdSGX"}},{"cell_type":"code","execution_count":56,"metadata":{"id":"OAIH7r5YdSGY","executionInfo":{"status":"ok","timestamp":1670739968024,"user_tz":300,"elapsed":319,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["NUM_OF_SAMPLES = 4\n","prompt = \"I loved the garlic bread\""]},{"cell_type":"markdown","source":["GPT 2"],"metadata":{"id":"I-uEKg-ndSGY"}},{"cell_type":"code","execution_count":57,"metadata":{"outputId":"8185e10a-f507-40e0-b02e-4edd1300289b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670739968344,"user_tz":300,"elapsed":1,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"NRMI82xkdSGY"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 5])"]},"metadata":{},"execution_count":57}],"source":["prompt_ids = tokenizer.encode(prompt)\n","inp = tensor(prompt_ids)[None].cuda()\n","inp.shape"]},{"cell_type":"code","execution_count":58,"metadata":{"outputId":"135627c4-a4c2-4691-8897-16b8e603bd8f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670739971096,"user_tz":300,"elapsed":1313,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"JAYMd0oSdSGY"},"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]}],"source":["preds = learn.model.generate(inp, max_length=50, do_sample=True, top_k=0, top_p=0.92, num_return_sequences=NUM_OF_SAMPLES, temperature=0.7)"]},{"cell_type":"code","execution_count":59,"metadata":{"outputId":"4a4907ac-9f25-4f14-96bf-3238654ec79c","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1670739971098,"user_tz":300,"elapsed":12,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"4MeZHcB_dSGY"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'I loved the garlic bread.  We also ordered the Cuban sandwich, which was excellent!  The bread was soft and very flavorful.  The Cuban sandwich was very flavorful and the sauce was to die for.  The Cuban sandwich was very good and'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":59}],"source":["tokenizer.decode(preds[0].cpu().numpy())"]},{"cell_type":"code","execution_count":60,"metadata":{"outputId":"89123e95-47e9-47fb-af25-0c659bacc63e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670739972532,"user_tz":300,"elapsed":3,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"sPT-E4-CdSGZ"},"outputs":[{"output_type":"stream","name":"stdout","text":["0: I loved the garlic bread.  We also ordered the Cuban sandwich, which was excellent!  The bread was soft and very flavorful.  The Cuban sandwich was very flavorful and the sauce was to die for.  The Cuban sandwich was very good and\n","1: I loved the garlic bread, and the decor was very nice. The music was pretty good too, so it was good to hear the music. \n","\n","The bar was very clean, and I really liked that it had a lot of seating.\n","2: I loved the garlic bread and the spicy garlic sauce! I also enjoyed the pita bread. The bread was soft and crunchy and the pita was soooo yummy!I'm not sure if this is a simple mistake on my part or\n","3: I loved the garlic bread and the tomato sauce was good. The service was great and they have a great happy hour. \n","\n","I'll be back for sure.Nice bar and the food was good. They have a nice selection of beer.\n"]}],"source":["for i, pred in enumerate(preds):\n","  print(\"{}: {}\".format(i, tokenizer.decode(pred, skip_special_tokens=True)))"]},{"cell_type":"markdown","source":["GPT3"],"metadata":{"id":"J5sA8AWjdSGZ"}},{"cell_type":"code","source":["pred = openai.Completion.create(\n","  model=\"ada:ft-new-york-university-2022-12-11-05-52-26\",\n","  prompt=prompt,\n","  max_tokens=50, n=NUM_OF_SAMPLES, temperature=0.7, top_p=0.92\n",")"],"metadata":{"id":"bIcucAs1dSGZ","executionInfo":{"status":"ok","timestamp":1670739978978,"user_tz":300,"elapsed":846,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","source":["for i in range(NUM_OF_SAMPLES):\n","  print(f\"Sample {i+1}: \")\n","  print(prompt + pred.choices[i].text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670739980273,"user_tz":300,"elapsed":2,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"353d2a09-2de8-474c-d663-dda4c0859998","id":"zmQNdvXPdSGZ"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample 1: \n","I loved the garlic bread at the restaurant, it was good and the fresh lemonade was just lovely! I would recommend it to anyone! I got the fried chicken and it was delicious! I had the fried chicken was a little bit of chicken but it was very good.\n","Sample 2: \n","I loved the garlic bread with the cheese and the pepperoni pizza. They have a variety of toppings. A great place to go for a quick bite at home. The staff was very friendly and we would definitely recommend this place to friends and family.\n","\n","The food\n","Sample 3: \n","I loved the garlic bread, as well as the chicken and cheese steak sandwich. I'm a big fan of having a diverse menu and this place was a perfect addition. The service was fast, friendly and knowledgeable. I highly recommend this place. END. END END END END\n","Sample 4: \n","I loved the garlic bread here. I also loved their Greek salad. It was so good. The only thing that was disappointing is that the service was a little slow. The guys who worked there were very nice and nice to talk to. The girl who had the salad was\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"gV1yXPCydmfJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Example 4: Garlic Naan"],"metadata":{"id":"_5TaCjV1dm71"}},{"cell_type":"code","execution_count":70,"metadata":{"id":"OP1Z0x9ndm71","executionInfo":{"status":"ok","timestamp":1670740031602,"user_tz":300,"elapsed":428,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"outputs":[],"source":["NUM_OF_SAMPLES = 4\n","prompt = \"I loved the garlic naan\""]},{"cell_type":"markdown","source":["GPT 2"],"metadata":{"id":"6zNiVbGUdm71"}},{"cell_type":"code","execution_count":71,"metadata":{"outputId":"e55d52b3-4dae-4fec-8f21-3cda5baa4b9f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670740032048,"user_tz":300,"elapsed":8,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"KtLawHLgdm71"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 6])"]},"metadata":{},"execution_count":71}],"source":["prompt_ids = tokenizer.encode(prompt)\n","inp = tensor(prompt_ids)[None].cuda()\n","inp.shape"]},{"cell_type":"code","execution_count":72,"metadata":{"outputId":"77ebda6a-e9dc-422a-fd2b-d56124ff24a6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670740032753,"user_tz":300,"elapsed":712,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"AVfAIUjJdm71"},"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]}],"source":["preds = learn.model.generate(inp, max_length=50, do_sample=True, top_k=0, top_p=0.92, num_return_sequences=NUM_OF_SAMPLES, temperature=0.7)"]},{"cell_type":"code","execution_count":73,"metadata":{"outputId":"d9cc061b-c933-45b3-bfea-9e1e10f10393","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1670740032754,"user_tz":300,"elapsed":7,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"45RS3nuodm71"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'I loved the garlic naan and the chicken tikka masala. The staff was very friendly and the food was very good. They also have a cool space in the back. I would definitely come back here again.I wish I could give'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":73}],"source":["tokenizer.decode(preds[0].cpu().numpy())"]},{"cell_type":"code","execution_count":74,"metadata":{"outputId":"d56c3bd7-fb50-4f9d-92b0-df61fd734bdd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670740032754,"user_tz":300,"elapsed":6,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"id":"o_LdsWtJdm72"},"outputs":[{"output_type":"stream","name":"stdout","text":["0: I loved the garlic naan and the chicken tikka masala. The staff was very friendly and the food was very good. They also have a cool space in the back. I would definitely come back here again.I wish I could give\n","1: I loved the garlic naan. The spice of the naan was good but it was a little spicy for my taste. The naan was huge and a good size. I would come back here again. The waitresses are very nice and the\n","2: I loved the garlic naan, which I love. I also ordered the hummus which was also great. The ambiance was a little noisy, but otherwise, I'm really happy to have found this place. I would highly recommend coming here and\n","3: I loved the garlic naan and the chicken and waffles! I will be back!My go to place for the food. The service is fast and friendly. The food is delicious and always fresh. I love this place!This place is so\n"]}],"source":["for i, pred in enumerate(preds):\n","  print(\"{}: {}\".format(i, tokenizer.decode(pred, skip_special_tokens=True)))"]},{"cell_type":"markdown","source":["GPT3"],"metadata":{"id":"Fx-SZ18Rdm72"}},{"cell_type":"code","source":["pred = openai.Completion.create(\n","  model=\"ada:ft-new-york-university-2022-12-11-05-52-26\",\n","  prompt=prompt,\n","  max_tokens=50, n=NUM_OF_SAMPLES, temperature=0.7, top_p=0.92\n",")"],"metadata":{"id":"AneP_nP9dm72","executionInfo":{"status":"ok","timestamp":1670740033585,"user_tz":300,"elapsed":835,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["for i in range(NUM_OF_SAMPLES):\n","  print(f\"Sample {i+1}: \")\n","  print(prompt + pred.choices[i].text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670740033586,"user_tz":300,"elapsed":7,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}},"outputId":"4130cebc-77a1-41b3-cf51-f61ef0fdbae8","id":"lcNVetlcdm72"},"execution_count":76,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample 1: \n","I loved the garlic naan, the king prawn and the meatballs. The lamb shank was great. My only disappointment was the service. The staff were incredibly slow and unhelpful. However, the food was good and the prices reasonable. The place is a bit\n","Sample 2: \n","I loved the garlic naan at the bistro.  They were so good that I have yet to make a complaint about their food.  We ordered a lot of items and it was good all.  I suggest the shrimp and grits.  Served with house\n","Sample 3: \n","I loved the garlic naan. I am getting the regular version next time. I was very pleased with the service and the food. My husband and I had the chicken nugget combo and we both enjoyed it. The chicken was cooked perfectly and the naan was crispy and\n","Sample 4: \n","I loved the garlic naan (my only complaint) and the nachos as well. The lox was great and the margaritas were refreshing after a long day at work. Overall great place to get a good night's sleep. I'll definitely be back! END\n"]}]},{"cell_type":"markdown","source":["So a few observations:\n","\n","1. It seems like the GPT-2 was better able to distinguish between Garlic Bread and Garlic Naan, which are from two different cultures. The GPT-2 was able to quickly generate sentences that stayed within context whereas the GPT-3 failed. It mixed the two dishes together. \n","2. When it came to sushi, both the models generated context aware sentences.\n","\n","These two observation point us in the direction that while we can generate context aware sentences with little data for finetuning the GPT-3, we will still need to feed it more data to fine-tune the model so that cases like Garlic Bread and Garlic Naan aren't confused. Furthermore, more data is needed because it can be seen that the finetuned GPT3 model is outputing stuff like `Lisa W. (Reviewed on 11/9/2010)`."],"metadata":{"id":"zw3Yw5dMeF1Z"}},{"cell_type":"code","source":[],"metadata":{"id":"yOu3CGHbffnL","executionInfo":{"status":"ok","timestamp":1670740033586,"user_tz":300,"elapsed":5,"user":{"displayName":"Ahmad Farhan Ishraq","userId":"14194620650428626995"}}},"execution_count":76,"outputs":[]}]}